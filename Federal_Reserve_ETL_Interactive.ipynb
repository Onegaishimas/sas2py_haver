{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Federal Reserve ETL Pipeline - Interactive Notebook\n",
    "\n",
    "This notebook provides an interactive interface for the Federal Reserve ETL Pipeline, allowing you to extract data from FRED and Haver Analytics APIs with real-time feedback and visualization.\n",
    "\n",
    "## Features\n",
    "- ‚úÖ FRED API integration with rate limiting\n",
    "- ‚úÖ Haver Analytics API integration\n",
    "- ‚úÖ Factory pattern for data source creation\n",
    "- ‚úÖ Comprehensive error handling\n",
    "- ‚úÖ Metadata retrieval and data validation\n",
    "- ‚úÖ Export to CSV, JSON, and Excel formats\n",
    "- ‚úÖ Interactive data visualization\n",
    "\n",
    "## Prerequisites\n",
    "- FRED_API_KEY environment variable set\n",
    "- Optional: HAVER_API_KEY for Haver Analytics\n",
    "- Network connectivity to API endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timedelta\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
    "\n",
    "# Federal Reserve ETL imports\n",
    "from federal_reserve_etl import (\n",
    "    create_data_source,\n",
    "    FREDDataSource,\n",
    "    HaverDataSource,\n",
    "    get_config_manager,\n",
    "    validate_source_credentials\n",
    ")\n",
    "from federal_reserve_etl.utils import (\n",
    "    ConnectionError,\n",
    "    AuthenticationError,\n",
    "    DataRetrievalError,\n",
    "    ValidationError,\n",
    "    setup_logging\n",
    ")\n",
    "\n",
    "# Setup logging for notebook\n",
    "logger = setup_logging(log_level=\"INFO\", enable_console=True)\n",
    "\n",
    "# Configure matplotlib for better plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Federal Reserve ETL Pipeline - Interactive Notebook Initialized\")\n",
    "print(f\"üìÅ Working Directory: {Path.cwd()}\")\n",
    "print(f\"üêç Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"üêº Pandas Version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. API Key Configuration and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check API key configuration\n",
    "fred_api_key = os.getenv('FRED_API_KEY')\n",
    "haver_api_key = os.getenv('HAVER_API_KEY')\n",
    "\n",
    "print(\"üîë API Key Status:\")\n",
    "print(f\"   FRED API Key: {'‚úÖ Set' if fred_api_key else '‚ùå Not Set'}\")\n",
    "if fred_api_key:\n",
    "    print(f\"   FRED Key Length: {len(fred_api_key)} characters (expected: 32)\")\n",
    "print(f\"   Haver API Key: {'‚úÖ Set' if haver_api_key else '‚ùå Not Set (Optional)'}\")\n",
    "\n",
    "# Validate credentials\n",
    "if fred_api_key:\n",
    "    try:\n",
    "        fred_valid = validate_source_credentials('fred')\n",
    "        print(f\"\\nüîç FRED Credential Validation: {'‚úÖ Valid' if fred_valid else '‚ùå Invalid'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ö†Ô∏è FRED Credential Validation Failed: {e}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Please set FRED_API_KEY environment variable to continue\")\n",
    "    print(\"   Example: os.environ['FRED_API_KEY'] = 'your_api_key_here'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Quick Start - FRED Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demonstration with Federal Funds Rate\n",
    "if fred_api_key:\n",
    "    print(\"üöÄ Quick Start: Extracting Federal Funds Rate (Last 30 Days)\")\n",
    "    \n",
    "    # Calculate date range\n",
    "    end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    try:\n",
    "        # Create FRED data source and extract data\n",
    "        with create_data_source('fred', api_key=fred_api_key) as fred:\n",
    "            print(f\"üìä Extracting FEDFUNDS from {start_date} to {end_date}\")\n",
    "            \n",
    "            df = fred.get_data(\n",
    "                variables=\"FEDFUNDS\",\n",
    "                start_date=start_date,\n",
    "                end_date=end_date\n",
    "            )\n",
    "            \n",
    "            print(f\"\\n‚úÖ Successfully extracted {len(df)} observations\")\n",
    "            print(f\"üìà Data range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "            # Display first few rows\n",
    "            print(\"\\nüìã Sample Data:\")\n",
    "            print(df.head().round(2))\n",
    "            \n",
    "            # Quick visualization\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(df.index, df['FEDFUNDS'], marker='o', linewidth=2, markersize=4)\n",
    "            plt.title('Federal Funds Rate - Last 30 Days', fontsize=14, fontweight='bold')\n",
    "            plt.xlabel('Date')\n",
    "            plt.ylabel('Rate (%)')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during quick start: {e}\")\n",
    "        print(\"üí° This might be due to weekends/holidays - try a longer date range\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è FRED API Key required for quick start demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Data Source Factory and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate data source factory pattern\n",
    "print(\"üè≠ Data Source Factory Demonstration\")\n",
    "\n",
    "# Get configuration manager\n",
    "config_mgr = get_config_manager()\n",
    "\n",
    "print(\"\\nüìã Available Data Sources:\")\n",
    "sources = ['fred', 'haver']\n",
    "\n",
    "for source in sources:\n",
    "    try:\n",
    "        # Test credential validation\n",
    "        is_valid = config_mgr.validate_credentials(source)\n",
    "        status = \"‚úÖ Valid\" if is_valid else \"‚ùå Invalid\"\n",
    "        \n",
    "        # Get missing credentials if any\n",
    "        missing = config_mgr.get_missing_credentials(source)\n",
    "        missing_str = f\" (Missing: {missing})\" if missing else \"\"\n",
    "        \n",
    "        print(f\"   {source.upper()}: {status}{missing_str}\")\n",
    "        \n",
    "        if is_valid:\n",
    "            # Get data source configuration\n",
    "            source_config = config_mgr.get_data_source_config(source)\n",
    "            print(f\"      Rate Limit: {source_config.get('rate_limit', 'Not specified')} requests/minute\")\n",
    "            \n",
    "            # Test factory creation\n",
    "            if source == 'fred' and fred_api_key:\n",
    "                ds = create_data_source(source, api_key=fred_api_key)\n",
    "                print(f\"      Factory Test: ‚úÖ Created {type(ds).__name__}\")\n",
    "            elif source == 'haver' and haver_api_key:\n",
    "                ds = create_data_source(source, api_key=haver_api_key)\n",
    "                print(f\"      Factory Test: ‚úÖ Created {type(ds).__name__}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"   {source.upper()}: ‚ùå Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Interactive Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive data extraction with user-friendly interface\n",
    "def extract_economic_data(variables, start_date, end_date, source='fred', api_key=None):\n",
    "    \"\"\"\n",
    "    Extract economic data with comprehensive error handling and reporting\n",
    "    \n",
    "    Args:\n",
    "        variables: Single variable (str) or list of variables\n",
    "        start_date: Start date (YYYY-MM-DD format or datetime)\n",
    "        end_date: End date (YYYY-MM-DD format or datetime)\n",
    "        source: Data source ('fred' or 'haver')\n",
    "        api_key: API key for the specified source\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (DataFrame, metadata_dict)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert single variable to list for consistent processing\n",
    "    if isinstance(variables, str):\n",
    "        variables = [variables]\n",
    "    \n",
    "    print(f\"üîÑ Starting Data Extraction\")\n",
    "    print(f\"   Source: {source.upper()}\")\n",
    "    print(f\"   Variables: {variables}\")\n",
    "    print(f\"   Date Range: {start_date} to {end_date}\")\n",
    "    \n",
    "    try:\n",
    "        # Create data source\n",
    "        with create_data_source(source, api_key=api_key) as ds:\n",
    "            print(f\"\\n‚úÖ Connected to {source.upper()} API\")\n",
    "            \n",
    "            # Extract data\n",
    "            df = ds.get_data(\n",
    "                variables=variables,\n",
    "                start_date=start_date,\n",
    "                end_date=end_date\n",
    "            )\n",
    "            \n",
    "            print(f\"üìä Extracted {len(df)} observations\")\n",
    "            \n",
    "            # Get metadata\n",
    "            metadata = ds.get_metadata(variables)\n",
    "            print(f\"üìã Retrieved metadata for {len(metadata)} variables\")\n",
    "            \n",
    "            # Display summary statistics\n",
    "            print(f\"\\nüìà Data Summary:\")\n",
    "            print(f\"   Date Range: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\")\n",
    "            print(f\"   Observations: {len(df)}\")\n",
    "            print(f\"   Variables: {list(df.columns)}\")\n",
    "            \n",
    "            # Check for missing data\n",
    "            missing_data = df.isnull().sum()\n",
    "            if missing_data.sum() > 0:\n",
    "                print(f\"\\n‚ö†Ô∏è Missing Data:\")\n",
    "                for var, missing in missing_data.items():\n",
    "                    if missing > 0:\n",
    "                        pct = (missing / len(df)) * 100\n",
    "                        print(f\"   {var}: {missing} observations ({pct:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"\\n‚úÖ No missing data detected\")\n",
    "            \n",
    "            return df, metadata\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Extraction failed: {e}\")\n",
    "        print(f\"üí° Error type: {type(e).__name__}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ Interactive extraction function loaded\")\n",
    "print(\"üí° Use extract_economic_data(variables, start_date, end_date, source, api_key) to extract data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Example: Multiple Economic Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract multiple key economic indicators\n",
    "if fred_api_key:\n",
    "    print(\"üìä Extracting Key Economic Indicators for 2023\")\n",
    "    \n",
    "    # Define variables and date range\n",
    "    key_indicators = [\"FEDFUNDS\", \"DGS10\", \"TB3MS\", \"UNRATE\", \"CPIAUCSL\"]\n",
    "    start_date = \"2023-01-01\"\n",
    "    end_date = \"2023-12-31\"\n",
    "    \n",
    "    try:\n",
    "        # Extract data\n",
    "        df, metadata = extract_economic_data(\n",
    "            variables=key_indicators,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            source='fred',\n",
    "            api_key=fred_api_key\n",
    "        )\n",
    "        \n",
    "        # Display metadata\n",
    "        print(\"\\nüìã Variable Descriptions:\")\n",
    "        for var, meta in metadata.items():\n",
    "            print(f\"   {var}: {meta.get('name', 'No description')}\")\n",
    "        \n",
    "        # Display sample data\n",
    "        print(\"\\nüìã Sample Data (First 10 Rows):\")\n",
    "        print(df.head(10).round(2))\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "        axes = axes.ravel()\n",
    "        \n",
    "        for i, col in enumerate(df.columns):\n",
    "            if i < len(axes):\n",
    "                # Plot data with proper handling of missing values\n",
    "                data_to_plot = df[col].dropna()\n",
    "                if len(data_to_plot) > 0:\n",
    "                    axes[i].plot(data_to_plot.index, data_to_plot.values, \n",
    "                               linewidth=2, marker='o', markersize=2)\n",
    "                    axes[i].set_title(f'{col}\\n{metadata[col].get(\"name\", \"\")[:50]}', \n",
    "                                    fontsize=10, fontweight='bold')\n",
    "                    axes[i].grid(True, alpha=0.3)\n",
    "                    axes[i].tick_params(axis='x', rotation=45)\n",
    "                else:\n",
    "                    axes[i].text(0.5, 0.5, f'No data for {col}', \n",
    "                               ha='center', va='center', transform=axes[i].transAxes)\n",
    "        \n",
    "        # Remove empty subplot\n",
    "        if len(df.columns) < len(axes):\n",
    "            fig.delaxes(axes[-1])\n",
    "        \n",
    "        plt.suptitle('Key Economic Indicators - 2023', fontsize=16, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Store data for later use\n",
    "        economic_indicators_2023 = df\n",
    "        economic_metadata = metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to extract economic indicators: {e}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è FRED API Key required for economic indicators demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 7. Data Export Capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate various export formats\n",
    "def export_data(df, metadata, base_filename=\"economic_data\", formats=['csv', 'json', 'excel']):\n",
    "    \"\"\"\n",
    "    Export data to multiple formats with metadata\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to export\n",
    "        metadata: Metadata dictionary\n",
    "        base_filename: Base name for output files\n",
    "        formats: List of formats to export ('csv', 'json', 'excel')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Paths of created files\n",
    "    \"\"\"\n",
    "    \n",
    "    output_dir = Path.cwd() / \"output\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    exported_files = {}\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(f\"üìÅ Exporting to: {output_dir}\")\n",
    "    \n",
    "    try:\n",
    "        # CSV Export\n",
    "        if 'csv' in formats:\n",
    "            csv_path = output_dir / f\"{base_filename}_{timestamp}.csv\"\n",
    "            df.to_csv(csv_path, index=True)\n",
    "            exported_files['csv'] = csv_path\n",
    "            print(f\"‚úÖ CSV exported: {csv_path.name} ({csv_path.stat().st_size:,} bytes)\")\n",
    "        \n",
    "        # JSON Export with metadata\n",
    "        if 'json' in formats:\n",
    "            json_path = output_dir / f\"{base_filename}_{timestamp}.json\"\n",
    "            export_data = {\n",
    "                'data': df.reset_index().to_dict('records'),\n",
    "                'metadata': metadata,\n",
    "                'export_info': {\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'observations': len(df),\n",
    "                    'variables': list(df.columns),\n",
    "                    'date_range': {\n",
    "                        'start': df.index.min().isoformat() if len(df) > 0 else None,\n",
    "                        'end': df.index.max().isoformat() if len(df) > 0 else None\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            import json\n",
    "            with open(json_path, 'w') as f:\n",
    "                json.dump(export_data, f, indent=2, default=str)\n",
    "            \n",
    "            exported_files['json'] = json_path\n",
    "            print(f\"‚úÖ JSON exported: {json_path.name} ({json_path.stat().st_size:,} bytes)\")\n",
    "        \n",
    "        # Excel Export with multiple sheets\n",
    "        if 'excel' in formats:\n",
    "            excel_path = output_dir / f\"{base_filename}_{timestamp}.xlsx\"\n",
    "            \n",
    "            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "                # Data sheet\n",
    "                df.to_excel(writer, sheet_name='Data', index=True)\n",
    "                \n",
    "                # Metadata sheet\n",
    "                if metadata:\n",
    "                    meta_df = pd.DataFrame.from_dict(metadata, orient='index')\n",
    "                    meta_df.to_excel(writer, sheet_name='Metadata', index=True)\n",
    "                \n",
    "                # Summary sheet\n",
    "                summary_data = {\n",
    "                    'Metric': ['Variables', 'Observations', 'Date Range Start', 'Date Range End', 'Export Date'],\n",
    "                    'Value': [\n",
    "                        len(df.columns),\n",
    "                        len(df),\n",
    "                        df.index.min().strftime('%Y-%m-%d') if len(df) > 0 else 'N/A',\n",
    "                        df.index.max().strftime('%Y-%m-%d') if len(df) > 0 else 'N/A',\n",
    "                        datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    ]\n",
    "                }\n",
    "                summary_df = pd.DataFrame(summary_data)\n",
    "                summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "            \n",
    "            exported_files['excel'] = excel_path\n",
    "            print(f\"‚úÖ Excel exported: {excel_path.name} ({excel_path.stat().st_size:,} bytes)\")\n",
    "        \n",
    "        return exported_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Test export if we have data\n",
    "if 'economic_indicators_2023' in locals() and len(economic_indicators_2023) > 0:\n",
    "    print(\"üíæ Testing Data Export...\")\n",
    "    exported = export_data(\n",
    "        df=economic_indicators_2023.head(50),  # Export first 50 rows for demo\n",
    "        metadata=economic_metadata,\n",
    "        base_filename=\"demo_economic_indicators\",\n",
    "        formats=['csv', 'json']  # Skip Excel for demo\n",
    "    )\n",
    "    \n",
    "    if exported:\n",
    "        print(f\"\\nüìä Export Summary:\")\n",
    "        for format_type, file_path in exported.items():\n",
    "            print(f\"   {format_type.upper()}: {file_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data available for export demonstration\")\n",
    "    print(\"üí° Run the previous cells to extract data first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 8. Error Handling and Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate comprehensive error handling\n",
    "def demonstrate_error_handling():\n",
    "    \"\"\"\n",
    "    Demonstrate various error scenarios and recovery patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç Error Handling Demonstration\\n\")\n",
    "    \n",
    "    # Test 1: Invalid API Key\n",
    "    print(\"Test 1: Invalid API Key\")\n",
    "    try:\n",
    "        invalid_key = '1234567890123456789012345678901X'  # 32 chars but invalid\n",
    "        with create_data_source('fred', api_key=invalid_key) as fred:\n",
    "            df = fred.get_data(variables=\"FEDFUNDS\", start_date=\"2023-01-01\", end_date=\"2023-01-31\")\n",
    "        print(\"‚ùå This should have failed!\")\n",
    "    except AuthenticationError as e:\n",
    "        print(f\"‚úÖ Correctly caught AuthenticationError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Caught different error: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test 2: Invalid Variable Code\n",
    "    if fred_api_key:\n",
    "        print(\"Test 2: Invalid Variable Code\")\n",
    "        try:\n",
    "            with create_data_source('fred', api_key=fred_api_key) as fred:\n",
    "                df = fred.get_data(\n",
    "                    variables=\"INVALID_VARIABLE_CODE_12345\",\n",
    "                    start_date=\"2023-01-01\",\n",
    "                    end_date=\"2023-01-31\"\n",
    "                )\n",
    "            print(\"‚ùå This should have failed!\")\n",
    "        except DataRetrievalError as e:\n",
    "            print(f\"‚úÖ Correctly caught DataRetrievalError: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Caught different error: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test 3: Invalid Date Range\n",
    "    if fred_api_key:\n",
    "        print(\"Test 3: Invalid Date Range (Start > End)\")\n",
    "        try:\n",
    "            with create_data_source('fred', api_key=fred_api_key) as fred:\n",
    "                df = fred.get_data(\n",
    "                    variables=\"FEDFUNDS\",\n",
    "                    start_date=\"2023-12-31\",  # Start after end\n",
    "                    end_date=\"2023-01-01\"\n",
    "                )\n",
    "            print(\"‚ùå This should have failed!\")\n",
    "        except ValidationError as e:\n",
    "            print(f\"‚úÖ Correctly caught ValidationError: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Caught different error: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # Test 4: Future Date Range\n",
    "    if fred_api_key:\n",
    "        print(\"Test 4: Future Date Range (No Data Available)\")\n",
    "        try:\n",
    "            future_start = (datetime.now() + timedelta(days=30)).strftime('%Y-%m-%d')\n",
    "            future_end = (datetime.now() + timedelta(days=60)).strftime('%Y-%m-%d')\n",
    "            \n",
    "            with create_data_source('fred', api_key=fred_api_key) as fred:\n",
    "                df = fred.get_data(\n",
    "                    variables=\"FEDFUNDS\",\n",
    "                    start_date=future_start,\n",
    "                    end_date=future_end\n",
    "                )\n",
    "            print(f\"‚ö†Ô∏è Unexpectedly succeeded - got {len(df)} rows\")\n",
    "        except DataRetrievalError as e:\n",
    "            print(f\"‚úÖ Correctly caught DataRetrievalError: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Caught different error: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Error handling demonstration complete\")\n",
    "\n",
    "# Run error handling demonstration\n",
    "demonstrate_error_handling()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 9. Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced features demonstration\n",
    "def create_economic_dashboard(variables, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Create a comprehensive economic data dashboard\n",
    "    \n",
    "    Args:\n",
    "        variables: List of FRED variable codes\n",
    "        start_date: Start date for data extraction\n",
    "        end_date: End date for data extraction\n",
    "    \"\"\"\n",
    "    \n",
    "    if not fred_api_key:\n",
    "        print(\"‚ö†Ô∏è FRED API Key required for dashboard\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Creating Economic Dashboard\")\n",
    "    print(f\"   Variables: {variables}\")\n",
    "    print(f\"   Period: {start_date} to {end_date}\")\n",
    "    \n",
    "    try:\n",
    "        # Extract data with progress reporting\n",
    "        df, metadata = extract_economic_data(\n",
    "            variables=variables,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            source='fred',\n",
    "            api_key=fred_api_key\n",
    "        )\n",
    "        \n",
    "        # Create comprehensive dashboard\n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        \n",
    "        # Time series plots\n",
    "        for i, col in enumerate(df.columns[:4]):  # Limit to first 4 variables\n",
    "            plt.subplot(2, 3, i+1)\n",
    "            data = df[col].dropna()\n",
    "            if len(data) > 0:\n",
    "                plt.plot(data.index, data.values, linewidth=2, color=f'C{i}')\n",
    "                plt.title(f'{col}\\n{metadata[col].get(\"name\", \"\")[:40]}...', \n",
    "                         fontsize=12, fontweight='bold')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.xticks(rotation=45)\n",
    "                \n",
    "                # Add trend line\n",
    "                x_numeric = np.arange(len(data))\n",
    "                z = np.polyfit(x_numeric, data.values, 1)\n",
    "                p = np.poly1d(z)\n",
    "                plt.plot(data.index, p(x_numeric), \"--\", alpha=0.7, color='red')\n",
    "        \n",
    "        # Correlation heatmap\n",
    "        plt.subplot(2, 3, 5)\n",
    "        correlation_matrix = df.corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                   square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "        plt.title('Variable Correlations', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Summary statistics\n",
    "        plt.subplot(2, 3, 6)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Create summary text\n",
    "        summary_text = \"üìä Dashboard Summary\\n\\n\"\n",
    "        summary_text += f\"üìÖ Period: {df.index.min().strftime('%Y-%m-%d')} to {df.index.max().strftime('%Y-%m-%d')}\\n\"\n",
    "        summary_text += f\"üìà Observations: {len(df):,}\\n\"\n",
    "        summary_text += f\"üìä Variables: {len(df.columns)}\\n\\n\"\n",
    "        \n",
    "        # Variable statistics\n",
    "        for col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "            if len(data) > 0:\n",
    "                mean_val = data.mean()\n",
    "                std_val = data.std()\n",
    "                summary_text += f\"{col}: Œº={mean_val:.2f}, œÉ={std_val:.2f}\\n\"\n",
    "        \n",
    "        plt.text(0.05, 0.95, summary_text, transform=plt.gca().transAxes,\n",
    "                fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        plt.suptitle('Federal Reserve Economic Data Dashboard', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return df, metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Dashboard creation failed: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Create sample dashboard\n",
    "if fred_api_key:\n",
    "    dashboard_variables = [\"FEDFUNDS\", \"DGS10\", \"UNRATE\", \"CPIAUCSL\"]\n",
    "    dashboard_data, dashboard_meta = create_economic_dashboard(\n",
    "        variables=dashboard_variables,\n",
    "        start_date=\"2020-01-01\",\n",
    "        end_date=\"2023-12-31\"\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è FRED API Key required for dashboard demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 10. Custom Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis functions for economic data\n",
    "def analyze_rate_changes(df, rate_column):\n",
    "    \"\"\"\n",
    "    Analyze rate changes and identify significant movements\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing rate data\n",
    "        rate_column: Column name containing rate data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Analysis results\n",
    "    \"\"\"\n",
    "    \n",
    "    if rate_column not in df.columns:\n",
    "        print(f\"‚ùå Column '{rate_column}' not found in DataFrame\")\n",
    "        return {}\n",
    "    \n",
    "    data = df[rate_column].dropna()\n",
    "    if len(data) < 2:\n",
    "        print(f\"‚ùå Insufficient data for analysis\")\n",
    "        return {}\n",
    "    \n",
    "    # Calculate changes\n",
    "    changes = data.diff().dropna()\n",
    "    \n",
    "    # Analysis results\n",
    "    analysis = {\n",
    "        'total_observations': len(data),\n",
    "        'current_rate': data.iloc[-1],\n",
    "        'period_start_rate': data.iloc[0],\n",
    "        'total_change': data.iloc[-1] - data.iloc[0],\n",
    "        'max_rate': data.max(),\n",
    "        'min_rate': data.min(),\n",
    "        'average_rate': data.mean(),\n",
    "        'volatility': data.std(),\n",
    "        'largest_increase': changes.max(),\n",
    "        'largest_decrease': changes.min(),\n",
    "        'increase_dates': changes[changes > 0].index.tolist(),\n",
    "        'decrease_dates': changes[changes < 0].index.tolist(),\n",
    "        'no_change_dates': changes[changes == 0].index.tolist()\n",
    "    }\n",
    "    \n",
    "    # Print analysis\n",
    "    print(f\"üìä Rate Analysis for {rate_column}\")\n",
    "    print(f\"   Period: {data.index[0].strftime('%Y-%m-%d')} to {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    print(f\"   Observations: {analysis['total_observations']:,}\")\n",
    "    print(f\"\\nüìà Rate Statistics:\")\n",
    "    print(f\"   Current Rate: {analysis['current_rate']:.2f}%\")\n",
    "    print(f\"   Starting Rate: {analysis['period_start_rate']:.2f}%\")\n",
    "    print(f\"   Total Change: {analysis['total_change']:+.2f}%\")\n",
    "    print(f\"   Range: {analysis['min_rate']:.2f}% to {analysis['max_rate']:.2f}%\")\n",
    "    print(f\"   Average: {analysis['average_rate']:.2f}%\")\n",
    "    print(f\"   Volatility (œÉ): {analysis['volatility']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Change Analysis:\")\n",
    "    print(f\"   Largest Increase: +{analysis['largest_increase']:.2f}%\")\n",
    "    print(f\"   Largest Decrease: {analysis['largest_decrease']:.2f}%\")\n",
    "    print(f\"   Rate Increases: {len(analysis['increase_dates'])} occasions\")\n",
    "    print(f\"   Rate Decreases: {len(analysis['decrease_dates'])} occasions\")\n",
    "    print(f\"   No Changes: {len(analysis['no_change_dates'])} occasions\")\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Rate over time\n",
    "    ax1.plot(data.index, data.values, linewidth=2, color='blue', label=rate_column)\n",
    "    ax1.axhline(y=analysis['average_rate'], color='red', linestyle='--', \n",
    "               alpha=0.7, label=f'Average ({analysis[\"average_rate\"]:.2f}%)')\n",
    "    ax1.fill_between(data.index, analysis['min_rate'], analysis['max_rate'], \n",
    "                    alpha=0.1, color='gray', label='Range')\n",
    "    ax1.set_title(f'{rate_column} Over Time', fontweight='bold')\n",
    "    ax1.set_ylabel('Rate (%)')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Rate changes\n",
    "    ax2.bar(changes.index, changes.values, width=1, \n",
    "           color=['green' if x > 0 else 'red' if x < 0 else 'gray' for x in changes.values])\n",
    "    ax2.axhline(y=0, color='black', linewidth=0.5)\n",
    "    ax2.set_title(f'{rate_column} Changes', fontweight='bold')\n",
    "    ax2.set_ylabel('Change (%)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "# Test analysis function\n",
    "if 'economic_indicators_2023' in locals() and 'FEDFUNDS' in economic_indicators_2023.columns:\n",
    "    print(\"üîç Analyzing Federal Funds Rate Changes...\\n\")\n",
    "    fed_funds_analysis = analyze_rate_changes(economic_indicators_2023, 'FEDFUNDS')\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Federal Funds Rate data not available for analysis\")\n",
    "    print(\"üí° Run the economic indicators extraction cell first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 11. Quick Commands Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick commands and utilities\n",
    "def show_available_functions():\n",
    "    \"\"\"\n",
    "    Display available functions and their usage\n",
    "    \"\"\"\n",
    "    \n",
    "    functions = {\n",
    "        'extract_economic_data()': 'Extract data from FRED or Haver APIs',\n",
    "        'export_data()': 'Export DataFrame to CSV, JSON, or Excel',\n",
    "        'create_economic_dashboard()': 'Create comprehensive data dashboard',\n",
    "        'analyze_rate_changes()': 'Analyze rate changes and movements',\n",
    "        'validate_source_credentials()': 'Validate API credentials',\n",
    "        'create_data_source()': 'Create FRED or Haver data source',\n",
    "        'get_config_manager()': 'Get configuration manager instance'\n",
    "    }\n",
    "    \n",
    "    print(\"üõ†Ô∏è Available Functions:\")\n",
    "    for func, desc in functions.items():\n",
    "        print(f\"   {func:<30} - {desc}\")\n",
    "    \n",
    "    print(f\"\\nüîë Required Environment Variables:\")\n",
    "    print(f\"   FRED_API_KEY                   - FRED API key (required)\")\n",
    "    print(f\"   HAVER_API_KEY                  - Haver Analytics API key (optional)\")\n",
    "    \n",
    "    print(f\"\\nüìä Common Variable Codes:\")\n",
    "    variables = {\n",
    "        'FEDFUNDS': 'Federal Funds Rate',\n",
    "        'DGS10': '10-Year Treasury Constant Maturity Rate',\n",
    "        'TB3MS': '3-Month Treasury Bill Rate',\n",
    "        'UNRATE': 'Unemployment Rate',\n",
    "        'CPIAUCSL': 'Consumer Price Index for All Urban Consumers',\n",
    "        'GDPC1': 'Real Gross Domestic Product',\n",
    "        'PAYEMS': 'All Employees: Total Nonfarm Payrolls'\n",
    "    }\n",
    "    \n",
    "    for code, desc in variables.items():\n",
    "        print(f\"   {code:<12} - {desc}\")\n",
    "    \n",
    "    print(f\"\\nüí° Quick Start Examples:\")\n",
    "    print(f\"   # Extract single variable\")\n",
    "    print(f\"   df, meta = extract_economic_data('FEDFUNDS', '2023-01-01', '2023-12-31', 'fred', fred_api_key)\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   # Export data\")\n",
    "    print(f\"   export_data(df, meta, 'my_data', ['csv', 'json'])\")\n",
    "    print(f\"   \")\n",
    "    print(f\"   # Analyze rate changes\")\n",
    "    print(f\"   analyze_rate_changes(df, 'FEDFUNDS')\")\n",
    "\n",
    "# Show available functions\n",
    "show_available_functions()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ Federal Reserve ETL Pipeline - Interactive Notebook Ready!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüí° To get started:\")\n",
    "print(\"   1. Ensure FRED_API_KEY environment variable is set\")\n",
    "print(\"   2. Run the data extraction examples above\")\n",
    "print(\"   3. Use the analysis and export functions as needed\")\n",
    "print(\"   4. Create custom visualizations and analysis\")\n",
    "print(\"\\nüìö All functions include comprehensive error handling and logging\")\n",
    "print(\"üîç Use help(function_name) for detailed documentation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env.claude",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
